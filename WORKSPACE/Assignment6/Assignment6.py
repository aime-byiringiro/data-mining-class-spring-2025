#importing the librariesimport numpy as npimport matplotlib.pyplot as pltimport pandas as pd#importing the dataset dataset = pd.read_csv('Social_Network_Ads.csv')X = dataset.iloc[:, :-1].to_numpy()y = dataset.iloc[:, -1].to_numpy()X = np.column_stack((X, X[:, 0] ** 2))X = np.column_stack((X, X[:, 1] ** 2))X = np.column_stack((X, X[:, 0] * X[:, 1])) #Splitting the dataset into the training set and testfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test =  train_test_split(X,                                                     y, test_size = 0.25,                                                     random_state = 0)#Feature scaling/ we don't need feature scaling from sklearn.preprocessing import StandardScaler sc = StandardScaler()X_train = sc.fit_transform(X_train)X_test = sc.transform(X_test)# Fitting the logistic regression  on training datataset from sklearn.linear_model import LogisticRegression classifier = LogisticRegression()classifier.fit(X_train, y_train)#predicting the test results y_pred = classifier.predict(X_test)from sklearn.metrics import confusion_matrix, accuracy_scoreprint(confusion_matrix(y_test, y_pred))print(accuracy_score(y_test, y_pred))from matplotlib.colors import ListedColormap# Phase 1: Generate mesh grid and prepare it for scalingX1, X2 = np.meshgrid(    np.arange(start=X[:, 0].min() - 1, stop=X[:, 0].max() + 1, step=0.1),    np.arange(start=X[:, 1].min() - 1, stop=X[:, 1].max() + 1, step=0.1))# Step 2: Flatten X1 and X2 and stack into 2D arrayX_grid_base = np.array([X1.ravel(), X2.ravel()]).Tprint(X_grid_base)# Step 3: Add polynomial features (X^2, Y^2, XY)X_poly_base = np.column_stack((    X_grid_base,    X_grid_base[:, 0] ** 2,    X_grid_base[:, 1] ** 2,    X_grid_base[:, 0] * X_grid_base[:, 1]))print(X_poly_base)# Step 4: Use scaler to transform thisX_poly_scaled = sc.transform(X_poly_base)print(X_poly_scaled)# Phase 3: Plotting decision boundaryplt.contourf(    X1,    X2,    classifier.predict(X_poly_scaled).reshape(X1.shape),    alpha=0.75,    cmap=ListedColormap(['red', 'green']))# Plot original data pointsfor i, j in enumerate(np.unique(y)):    plt.scatter(        X_train[y_train == j, 0],        X_train[y_train == j, 1],        c=ListedColormap(['red', 'green'])(i),        label=j    )plt.title('Logistic Regression (Polynomial Features)')plt.xlabel('Age (scaled)')plt.ylabel('Estimated Salary (scaled)')plt.legend()plt.show()