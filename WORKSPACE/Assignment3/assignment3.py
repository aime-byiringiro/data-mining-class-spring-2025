# Multiple Linear Regression# Importing the librariesimport numpy as npimport matplotlib.pyplot as pltimport pandas as pd# Importing the datasetdataset = pd.read_csv('Crime_Data.csv')X = dataset.iloc[:, :-1].to_numpy()y = dataset.iloc[:, -1].to_numpy()# Splitting the dataset into the Training set and Test setfrom sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1,                                                    random_state = 0)# Training the Multiple Linear Regression model on the Training setfrom sklearn.linear_model import LinearRegressionregressor = LinearRegression()regressor.fit(X_train, y_train)# Predicting the Test set resultsy_pred = regressor.predict(X_test)# Building the optimal model using Backward Elimination# Feature Scalingfrom sklearn.preprocessing import StandardScalersc_X = StandardScaler()X_train = sc_X.fit_transform(X_train)X_test = sc_X.transform(X_test)sc_y = StandardScaler()y_train = sc_y.fit_transform(y_train.reshape(len(y_train), 1)).flatten()# Backward Elimination# Backward Eliminationimport statsmodels.api as sm X_train = sm.add_constant(X_train).astype(np.float64)X_opt = X_train[:, [0,1,2,3,4,5,6]]regressor_opt = sm.OLS(endog = y_train, exog = X_opt).fit()print(regressor_opt.summary())X_opt = X_train[:, [0,1,2,4,5,6]]regressor_opt = sm.OLS(endog = y_train, exog = X_opt).fit()print(regressor_opt.summary())X_opt = X_train[:, [0,1,2,4,5]]regressor_opt = sm.OLS(endog = y_train, exog = X_opt).fit()print(regressor_opt.summary())X_opt = X_train[:, [0,1,2,4]]regressor_opt = sm.OLS(endog = y_train, exog = X_opt).fit()print(regressor_opt.summary())X_test = sc_X.transform(X_test)X_test = sm.add_constant(X_test).astype(np.float64)y_pred = regressor_opt.predict(X_test[:, [0,1,2,4]])print("Coefficients:", regressor_opt.params)# Adding the new data for predictionnew_data = np.array([[500, 50, 40, 30, 20, 10]])  # Ensure the new_data is 2D (same as the training data)new_data_scaled = sc_X.transform(new_data)  # The new data has the same number of features as training data# Adding the constant to the new data for prediction (same as in backward elimination)new_data_scaled = sm.add_constant(new_data_scaled)#add teh rmoved colum new_data_scaled = np.append([[1]], new_data_scaled, axis=1)predicted_y = regressor_opt.predict(new_data_scaled[:, [0,1,2,4]])print("Predicted value of Y is:", predicted_y)#call the value values were used in optimal #print the predict opt